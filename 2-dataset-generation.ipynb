{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load your OpenAI API key from an environment variable\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "1                                ***BREAKING NEWS***   \n",
      "2  **Title: New Study Reveals Surprising Economic...   \n",
      "3  Title: Record-breaking Marathon Runner Sets Ne...   \n",
      "4  Title: Unprecedented Avalanche Strikes Coastal...   \n",
      "5  Title: Breaking News: Global Market Soars as N...   \n",
      "\n",
      "                                                text  label  \n",
      "1  **Landmark Trade Deal Reached Between Global P...      0  \n",
      "2  In a groundbreaking study released today by th...      0  \n",
      "3  In a stunning display of endurance and athleti...      0  \n",
      "4  In a shocking turn of events, a massive avalan...      0  \n",
      "5  In a historic economic development that has st...      0  \n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Load your OpenAI API key from an environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "def generate_article():\n",
    "    topics = [\n",
    "        \"a recent scientific breakthrough\",\n",
    "        \"the latest political events\",\n",
    "        \"a major technological innovation\",\n",
    "        \"an unexpected natural disaster\",\n",
    "        \"a significant economic development\",\n",
    "        \"a new health study results\",\n",
    "        \"a major sports event\"\n",
    "    ]\n",
    "    topic = random.choice(topics)\n",
    "    messages = []\n",
    "    prompt = f\"You are a news writer. Please generate a fake news article about {topic}.\"\n",
    "    messages.append({\"role\": \"system\", \"content\": prompt})\n",
    "    \n",
    "    def _openai():\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    article_text = _openai()\n",
    "    # Extract the title from the article (assuming it's the first line followed by two newlines)\n",
    "    title_end_index = article_text.find('\\n\\n')\n",
    "    if title_end_index != -1:\n",
    "        title = article_text[:title_end_index].strip()\n",
    "        text = article_text[title_end_index+2:].strip()  # the rest of the text after the title\n",
    "    else:\n",
    "        title = \"Generated Article\"\n",
    "        text = article_text\n",
    "    \n",
    "    return {'title': title, 'text': text, 'label': 0}\n",
    "\n",
    "# Generate 100 articles\n",
    "articles = [generate_article() for _ in range(100)]\n",
    "\n",
    "# Create a DataFrame for the generated dataset\n",
    "generated_articles = pd.DataFrame(articles)\n",
    "generated_articles.index += 1  # Adjust index to start from 1\n",
    "\n",
    "# Save the generated articles to CSV\n",
    "generated_articles.to_csv('./raw-data/generated_articles.csv', index_label='index')\n",
    "\n",
    "# Print the first few rows of the generated articles\n",
    "print(generated_articles.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "POSIX\n",
      "Darwin | 23.5.0\n",
      "Datetime: 2024-05-28 16:52:11\n",
      "Python Version: 3.12.1\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
